{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting time series training with SARIMA model...\n",
      "\n",
      "Optimizing Seasonal ARIMA for EN-US...\n",
      "Best SARIMA parameters: ((0, 1, 2), (0, 1, 2, 12), 1905.0880349722536) for EN-US\n",
      "Optimizing Seasonal ARIMA for ES-ES...\n",
      "Best SARIMA parameters: ((0, 1, 2), (0, 1, 2, 12), 1837.8102462478896) for ES-ES\n",
      "\n",
      "Time series model training completed in 0.84 minutes\n",
      "\n",
      "Model plots are stored in reports > images > model_plots folder\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time,os,re,csv,sys,xlrd,yaml,glob\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import joblib\n",
    "import math\n",
    "from itertools import product \n",
    "import statsmodels.api as sm\n",
    "\n",
    "def ingest_processed_dataset():\n",
    "\n",
    "    # Function to load yaml configuration file\n",
    "    def load_config(config_name):\n",
    "        with open(os.path.join(config_path, config_name), 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "\n",
    "        return config\n",
    "\n",
    "    config_path = \"conf/base\"\n",
    "\n",
    "    config = load_config(\"catalog.yml\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "def create_folders(root_path, img_path, subfolders):\n",
    "               \n",
    "        img_folder = os.path.join(root_path, img_path)\n",
    "        \n",
    "        # check if images folder exist in reports, if not create one\n",
    "        if not os.path.exists(img_folder):\n",
    "            os.makedirs(img_folder, exist_ok=True)\n",
    "        \n",
    "        # loop through the list of folders we want to create within the images folder\n",
    "        for sf in subfolders:\n",
    "            if not os.path.exists(os.path.join(img_folder, sf)):\n",
    "                os.makedirs(os.path.join(img_folder, sf), exist_ok=True)\n",
    "                \n",
    "def model_SARIMA_auto(config, df, label, freq = 'W', n_periods = 15):\n",
    "    \n",
    "    # filter the data\n",
    "    ts = df[['TaskDate', 'TaskCount']].set_index('TaskDate').resample(freq).sum()\n",
    "\n",
    "    # iterate through the range of p,d,q, P,D,Q and obtain the best (lowes) AIC\n",
    "    p = range(0, 3)\n",
    "    d = range(1,2)\n",
    "    q = range(0, 3)\n",
    "    pdq = list(product(p, d, q))\n",
    "    seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(product(p, d, q))]\n",
    "    print(f\"Optimizing Seasonal ARIMA for {label}...\")\n",
    "\n",
    "    aic = []\n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "#             try:\n",
    "            model = sm.tsa.statespace.SARIMAX(ts['TaskCount'],\n",
    "                                            order=param,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "            results = model.fit()\n",
    "            aic.append((param, param_seasonal, results.aic))\n",
    "#             except:\n",
    "#                 continue\n",
    "    \n",
    "    # get model best parameters and aic\n",
    "    best_params = min(aic, key=lambda x:x[2])\n",
    "    print(f\"Best SARIMA parameters: {best_params} for {label}\")\n",
    "    \n",
    "    # finalize and fit the best model with best parameters\n",
    "    model_SARIMA = sm.tsa.statespace.SARIMAX(ts['TaskCount'],\n",
    "                                order= best_params[0],\n",
    "                                seasonal_order = best_params[1],\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "    \n",
    "    # save best model as pickle (serialized) file\n",
    "    joblib.dump(model_SARIMA, os.path.join(config[\"project_path\"], config[\"models\"], \"model_SARIMA_\" + label + '_' + freq + '.pkl'))\n",
    "\n",
    "    results = model_SARIMA.fit()\n",
    "    aic = round(best_params[2],2)\n",
    "      \n",
    "    # obtain the model prediction from the start of the data - baseline is formed from the mean predicted and the CIs\n",
    "    pred = results.get_prediction(start=min(ts.index))\n",
    "    pred_ci = pred.conf_int()\n",
    "    \n",
    "    # plot model results\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax = ts['TaskCount'].plot(label='actual')\n",
    "    pred.predicted_mean.plot(ax=ax, label='predicted', color='darkgreen', alpha=.7, linewidth=1, linestyle='dashed')\n",
    "    ax.fill_between(pred_ci.index,\n",
    "                    pred_ci.iloc[:, 0],\n",
    "                    pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "    legend = plt.legend(loc='upper left')  # remove later\n",
    "    legend.get_frame().set_alpha(0) # remove later\n",
    "    ax.ticklabel_format(useOffset=False, style='plain', axis='y') # remove later\n",
    "    plt.title(f\"SARIMA model forecast (W) - {label}, AIC = {aic}\") # remove later\n",
    "    ax.set_ylabel(\"Total Task Counts\")\n",
    "    sns.despine()\n",
    "    \n",
    "    \n",
    "    fc_start = max(ts.index) + timedelta(days=1)\n",
    "    index_of_fc = pd.date_range(fc_start, periods=n_periods, freq='W').tolist()\n",
    "    \n",
    "    pred_dy = results.get_prediction(start=fc_start , end=max(index_of_fc))\n",
    "    pred_dy_ci = pred_dy.conf_int()\n",
    "    \n",
    "    pred_dy.predicted_mean.plot(ax=ax, label='forecast', color='red', linewidth=1, linestyle='dashed', alpha=0.7)\n",
    "    ax.fill_between(pred_dy_ci.index,\n",
    "                    pred_dy_ci.iloc[:, 0],\n",
    "                    pred_dy_ci.iloc[:, 1], color='k', alpha=.25)\n",
    "    \n",
    "    ax.fill_betweenx(ax.get_ylim(), pd.Timestamp(fc_start), max(index_of_fc),\n",
    "                     alpha=.1, zorder=-1) \n",
    "    legend = plt.legend(loc='upper left')\n",
    "    legend.get_frame().set_alpha(0)\n",
    "    ax.ticklabel_format(useOffset=False, style='plain', axis='y')\n",
    "    plt.title(f\"SARIMA model forecast (W) - {label}, AIC = {aic}\")\n",
    "    sns.despine()\n",
    "    \n",
    "    # Adjusted baseline - if lower ci is > 0, get the lowest value of lower_ci\n",
    "    adjusted_baseline = min(pred_ci[pred_ci['lower TaskCount'] > 0]['lower TaskCount'])\n",
    "    ax.axhline(adjusted_baseline, ls='--', color='lightseagreen', linewidth=1)\n",
    "    plt.savefig(os.path.join(config[\"project_path\"], config[\"reports\"][\"images\"], \"model_plots/mp_\" + label + \"_\" + freq + \".jpeg\"))\n",
    "    \n",
    "    plt.close()\n",
    "       \n",
    "    return pred, pred_ci, pred_dy, pred_dy_ci, label                \n",
    "                        \n",
    "def generate_baselines(pred, pred_ci, pred_dy, pred_dy_ci, label):\n",
    "    \n",
    "    # Get Weekly predicted table - mean prediction from the model is used as Weekly Baseline\n",
    "    W_predicted = pd.DataFrame()\n",
    "    W_predicted['W_baseline'] = pred.predicted_mean\n",
    "    W_predicted['W_lower_bl'] = pred_ci.iloc[:, 0]\n",
    "    try:\n",
    "        adjusted_baseline = min(pred_ci[pred_ci['lower TaskCount'] > 0]['lower TaskCount'])\n",
    "        W_predicted['W_lower_bl'] = np.where(W_predicted['W_lower_bl'] <= 0, adjusted_baseline, W_predicted['W_lower_bl'])\n",
    "    except:\n",
    "        W_predicted['W_lower_bl'] = np.where(W_predicted['W_lower_bl'] <= 0, W_predicted['W_baseline'], W_predicted['W_lower_bl'])\n",
    "    W_predicted['W_upper_bl'] = pred_ci.iloc[:, 1]\n",
    "    W_predicted['month_num'] = pd.Series(W_predicted.index).dt.strftime('%m').astype(int).tolist()\n",
    "    W_predicted['month'] = pd.Series(W_predicted.index).dt.month_name().str.slice(stop=3).tolist()   #.dt.strftime('%m')\n",
    "    W_predicted['week_in_month'] = pd.to_numeric(W_predicted.index.day/7)\n",
    "    W_predicted['week_in_month'] = W_predicted['week_in_month'].apply(lambda x: math.ceil(x))\n",
    "    W_predicted['Language'] = label\n",
    "    W_baseline = W_predicted.groupby(['Language','month_num','month','week_in_month']).mean().reset_index().sort_values(['month_num', 'week_in_month'])\n",
    "    W_baseline = W_baseline[['Language', 'month', 'week_in_month','W_baseline', 'W_lower_bl', 'W_upper_bl']]\n",
    "    \n",
    "    # Get Monthly predicted table - aggregated from the Weekly baseline\n",
    "    M_predicted = W_predicted[['W_baseline', 'W_lower_bl', 'W_upper_bl']].resample('M').sum()\n",
    "    M_predicted.columns = ['M_baseline', 'M_lower_bl', 'M_upper_bl']\n",
    "    M_predicted['Language'] =label\n",
    "    M_predicted['month_num'] = pd.Series(M_predicted.index).dt.strftime('%m').astype(int).tolist()\n",
    "    M_predicted['month'] = pd.Series(M_predicted.index).dt.month_name().str.slice(stop=3).tolist() \n",
    "    M_baseline = M_predicted.groupby(['Language','month_num','month']).mean().reset_index().sort_values('month_num')\n",
    "    M_baseline = M_baseline[['Language','month','M_baseline', 'M_lower_bl', 'M_upper_bl']]\n",
    "    \n",
    "    # Get Quarterly predicted table - aggregated from the Monthly baseline\n",
    "    Q_predicted = M_predicted[['M_baseline', 'M_lower_bl', 'M_upper_bl']].resample('Q').sum()\n",
    "    Q_predicted.columns = ['Q_baseline', 'Q_lower_bl', 'Q_upper_bl']\n",
    "    Q_predicted['Language'] = label\n",
    "    Q_predicted['month_num'] = pd.Series(Q_predicted.index).dt.strftime('%m').astype(int).tolist()\n",
    "    Q_predicted['month'] = pd.Series(Q_predicted.index).dt.month_name().str.slice(stop=3).tolist() \n",
    "    Q_baseline = Q_predicted.groupby(['Language','month_num','month']).mean().reset_index().sort_values(['month_num'])\n",
    "    conditions  = [ Q_baseline['month_num'] == 3, Q_baseline['month_num'] == 6, Q_baseline['month_num'] == 9, Q_baseline['month_num'] == 12]\n",
    "    quarter_name, quarter_num = [ 'Q1', 'Q2', 'Q3', 'Q4'], [1,2,3,4]\n",
    "    Q_baseline['quarter'] = np.select(conditions, quarter_name, default=np.nan)\n",
    "    Q_baseline['q'] = np.select(conditions, quarter_num, default=np.nan).astype(int)\n",
    "    Q_baseline = Q_baseline[['Language','quarter','Q_baseline', 'Q_lower_bl', 'Q_upper_bl']]\n",
    "    \n",
    "    W_forecast = pd.DataFrame()\n",
    "    W_forecast['W_forecast'] = pred_dy.predicted_mean\n",
    "    W_forecast['W_lower_fc'] = pred_dy_ci.iloc[:, 0]  \n",
    "    try:\n",
    "        adjusted_baseline_2 = min(pred_dy_ci[pred_dy_ci['lower TaskCount'] > 0]['lower TaskCount'])\n",
    "        W_forecast['W_lower_fc'] = np.where(W_forecast['W_lower_fc'] <= 0, adjusted_baseline_2, W_forecast['W_lower_fc'])\n",
    "    except:\n",
    "        W_forecast['W_lower_fc'] = np.where(W_forecast['W_lower_fc'] <= 0, W_forecast['W_forecast'], W_forecast['W_lower_fc'])\n",
    "    W_forecast['W_upper_fc'] = pred_dy_ci.iloc[:, 1]\n",
    "    W_forecast['month_num'] = pd.Series(W_forecast.index).dt.strftime('%m').astype(int).tolist()\n",
    "    W_forecast['month'] = pd.Series(W_forecast.index).dt.month_name().str.slice(stop=3).tolist()   #.dt.strftime('%m')\n",
    "    W_forecast['week_in_month'] = pd.to_numeric(W_forecast.index.day/7)\n",
    "    W_forecast['week_in_month'] = W_forecast['week_in_month'].apply(lambda x: math.ceil(x))\n",
    "    W_forecast['Language'] = label\n",
    "    W_forecast = W_forecast[['Language', 'month', 'week_in_month', 'W_forecast', 'W_lower_fc', 'W_upper_fc']]\n",
    "    \n",
    "    M_forecast = W_forecast[['W_forecast', 'W_lower_fc', 'W_upper_fc']].resample('M').sum()\n",
    "    M_forecast.columns = ['M_forecast', 'M_lower_fc', 'M_upper_fc']\n",
    "    M_forecast['Language'] = label\n",
    "    M_forecast['month_num'] = pd.Series(M_forecast.index).dt.strftime('%m').astype(int).tolist()\n",
    "    M_forecast['month'] = pd.Series(M_forecast.index).dt.month_name().str.slice(stop=3).tolist() \n",
    "    M_forecast = M_forecast[['Language', 'month', 'M_forecast', 'M_lower_fc', 'M_upper_fc']]   \n",
    "    \n",
    "    Q_forecast = M_forecast[['M_forecast', 'M_lower_fc', 'M_upper_fc']].resample('Q').sum()\n",
    "    Q_forecast.columns = ['Q_forecast', 'Q_lower_fc', 'Q_upper_fc']\n",
    "    Q_forecast['Language'] = label\n",
    "    Q_forecast['month_num'] = pd.Series(Q_forecast.index).dt.strftime('%m').astype(int).tolist()\n",
    "    Q_forecast['month'] = pd.Series(Q_forecast.index).dt.month_name().str.slice(stop=3).tolist() \n",
    "    conditions = [Q_forecast['month_num'] == 3, Q_forecast['month_num'] == 6, Q_forecast['month_num'] == 9, Q_forecast['month_num'] == 12]\n",
    "    quarter_name, quarter_num = [ 'Q1', 'Q2', 'Q3', 'Q4'], [1,2,3,4]\n",
    "    Q_forecast['quarter'] = np.select(conditions, quarter_name, default=np.nan)\n",
    "    Q_forecast['q'] = np.select(conditions, quarter_num, default=np.nan).astype(int)\n",
    "    Q_forecast = Q_forecast.sort_values(['month_num'])\n",
    "    Q_forecast = Q_forecast[['Language','quarter','Q_forecast', 'Q_lower_fc', 'Q_upper_fc']]\n",
    "    \n",
    "    W_baseline[['W_baseline', 'W_lower_bl', 'W_upper_bl']] = W_baseline[['W_baseline', 'W_lower_bl', 'W_upper_bl']].astype(int)\n",
    "    M_baseline[['M_baseline', 'M_lower_bl', 'M_upper_bl']] = M_baseline[['M_baseline', 'M_lower_bl', 'M_upper_bl']].astype(int)\n",
    "    Q_baseline[['Q_baseline', 'Q_lower_bl', 'Q_upper_bl']] = Q_baseline[['Q_baseline', 'Q_lower_bl', 'Q_upper_bl']].astype(int)\n",
    " \n",
    "    W_forecast[['W_forecast', 'W_lower_fc', 'W_upper_fc']] = W_forecast[['W_forecast', 'W_lower_fc', 'W_upper_fc']].astype(int)\n",
    "    M_forecast[['M_forecast', 'M_lower_fc', 'M_upper_fc']] = M_forecast[['M_forecast', 'M_lower_fc', 'M_upper_fc']].astype(int) \n",
    "    Q_forecast[['Q_forecast', 'Q_lower_fc', 'Q_upper_fc']] = Q_forecast[['Q_forecast', 'Q_lower_fc', 'Q_upper_fc']].astype(int) \n",
    "    \n",
    "    return W_baseline, M_baseline, Q_baseline, W_forecast, M_forecast, Q_forecast\n",
    "\n",
    "def write_baseline_report_to_excel(wb, mb, qb, wf, mf, qf, encoding=None):\n",
    "    \n",
    "    config = ingest_processed_dataset()\n",
    "    \n",
    "    # store all 4 reports into a dictionary set\n",
    "    list_of_datasets = {\"Weekly Baseline\" : wb,\n",
    "                        \"Monthly Baseline\" : mb,\n",
    "                        \"Quarterly Baseline\" : qb,\n",
    "                        \"Weekly Forecast\" : wf,\n",
    "                        \"Monthly Forecast\" : mf,\n",
    "                        \"Quarterly Forecast\" : qf}\n",
    "    \n",
    "    with pd.ExcelWriter(os.path.join(config[\"project_path\"], config[\"reports\"][\"predictions\"], 'Workflow_AI_Baseline_Report.xlsx')) as writer:  \n",
    "        for key, value in list_of_datasets.items():\n",
    "            value.to_excel(writer, sheet_name=key, index=False, encoding=None)\n",
    "\n",
    "def model_train(df, label, freq = 'W', n_periods = 15, test=False): \n",
    "    \n",
    "    config = ingest_processed_dataset()\n",
    "        \n",
    "    pred, pred_ci, pred_dy, pred_dy_ci, label = model_SARIMA_auto(config, df, label, freq = 'W', n_periods = 15)\n",
    "    \n",
    "    return pred, pred_ci, pred_dy, pred_dy_ci, label\n",
    "    \n",
    "def model_predict(pred, pred_ci, pred_dy, pred_dy_ci, label, model=None, steps = 15, test=False):\n",
    "    \n",
    "    W_baseline, M_baseline, Q_baseline, W_forecast, M_forecast, Q_forecast = generate_baselines(pred, pred_ci, pred_dy, pred_dy_ci, label)\n",
    "    \n",
    "    return W_baseline, M_baseline, Q_baseline, W_forecast, M_forecast, Q_forecast\n",
    "    \n",
    "# def model_load(test=False):\n",
    "#     \"\"\"\n",
    "#     example funtion to load model\n",
    "#     \"\"\"\n",
    "#     if test : \n",
    "#         print( \"... loading test version of model\" )\n",
    "#         model = joblib.load(os.path.join(\"models\",\"test.joblib\"))\n",
    "#         return(model)\n",
    "\n",
    "#     if not os.path.exists(SAVED_MODEL):\n",
    "#         exc = \"Model '{}' cannot be found did you train the full model?\".format(SAVED_MODEL)\n",
    "#         raise Exception(exc)\n",
    "    \n",
    "#     model = joblib.load(SAVED_MODEL)\n",
    "#     return(model)\n",
    "\n",
    "def model_train_predict(eda_summary):\n",
    "    \n",
    "    freq = 'W'\n",
    "    steps = 15\n",
    "\n",
    "    config = ingest_processed_dataset()\n",
    "    \n",
    "    subfolder_list = ['model_plots']\n",
    "    create_folders(config[\"project_path\"], config[\"reports\"][\"images\"], subfolder_list)\n",
    "    \n",
    "    # Start exploratory data analysis process\n",
    "    print(\"\\nStarting time series training with SARIMA model...\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    wb, mb, qb, wf, mf, qf = [],[],[],[],[],[]\n",
    "    for f in glob.glob(os.path.join(os.path.join(config[\"project_path\"], config[\"data_path\"][\"output\"], \"*.csv\"))):\n",
    "    \n",
    "        # get labels or filenames\n",
    "        fname = os.path.basename(f)\n",
    "        start = fname.find(\"ts_\") + len(\"ts_\")\n",
    "        end = fname.find(\".csv\")\n",
    "        label = fname[start:end]\n",
    "\n",
    "        df = pd.read_csv(f)\n",
    "        \n",
    "        #convert date columns as datetime\n",
    "        df['TaskDate'] = pd.to_datetime(df['TaskDate'])  \n",
    "        \n",
    "        pred, pred_ci, pred_dy, pred_dy_ci, label = model_train(df, label, freq, steps, test=False)\n",
    "        W_baseline, M_baseline, Q_baseline, W_forecast, M_forecast, Q_forecast = model_predict(pred, pred_ci, pred_dy, pred_dy_ci, label, model=None, steps = 15, test=False)\n",
    "        wb.append(W_baseline)\n",
    "        mb.append(M_baseline)\n",
    "        qb.append(Q_baseline)\n",
    "        wf.append(W_forecast)\n",
    "        mf.append(M_forecast)\n",
    "        qf.append(Q_forecast)\n",
    "        \n",
    "    wb = pd.concat(wb, ignore_index=True)\n",
    "    mb = pd.concat(mb, ignore_index=True)  \n",
    "    mb = pd.merge(mb,eda_summary[['Language','lowest_2_mths', 'highest_2_mths', 'overlap_confidence']],on='Language', how='left')\n",
    "    qb = pd.concat(qb, ignore_index=True)    \n",
    "    wf = pd.concat(wf, ignore_index=True) \n",
    "    mf = pd.concat(mf, ignore_index=True)\n",
    "    mf = pd.merge(mf,eda_summary[['Language','lowest_2_mths', 'highest_2_mths', 'overlap_confidence']],on='Language', how='left')\n",
    "    qf = pd.concat(qf, ignore_index=True)\n",
    "    \n",
    "    write_baseline_report_to_excel(wb, mb, qb, wf, mf, qf, encoding=None)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    processing_time = round((end_time - start_time)/60,2)\n",
    "        \n",
    "    print(f\"\\nTime series model training completed in {processing_time} minutes\")   \n",
    "    print(f\"\\nModel plots are stored in reports > images > model_plots folder\")   \n",
    "    \n",
    "    return pred, pred_ci, pred_dy, pred_dy_ci, label        \n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #eda_summary = []\n",
    "    model_train_predict(eda_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azt",
   "language": "python",
   "name": "azt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
